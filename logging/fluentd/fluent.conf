<source>
  @type forward # Используем in_forward плагин для приема логов
                # Use in_forward plugin for log receiving
                # https://docs.fluentd.org/v0.12/articles/in_forward
  port 24224
  bind 0.0.0.0
</source>

<filter service.post> # фильтр для парсинга json логов
  @type parser
  format json
  key_name log
</filter>

# <filter service.ui> # парсим, используя regexp
#   @type parser
#   format /\[(?<time>[^\]]*)\]  (?<level>\S+) (?<user>\S+)[\W]*service=(?<service>\S+)[\W]*event=(?<event>\S+)[\W]*(?:path=(?<path>\S+)[\W]*)?request_id=(?<request_id>\S+)[\W]*(?:remote_addr=(?<remote_addr>\S+)[\W]*)?(?:method= (?<method>\S+)[\W]*)?(?:response_status=(?<response_status>\S+)[\W]*)?(?:message='(?<message>[^\']*)[\W]*)?/
#   key_name log
# </filter>

<filter service.ui> # парсим, используя grok
  @type parser
  key_name log
  format grok
  grok_pattern %{RUBY_LOGGER}
</filter>

<filter service.ui>
  @type parser
  format grok
  grok_pattern service=%{WORD:service} \| event=%{WORD:event} \| request_id=%{GREEDYDATA:request_id} \| message='%{GREEDYDATA:message}'
  key_name message
  reserve_data true
</filter>

<match *.**>
  @type copy    # Используем copy плагин, чтобы переправить все входящие логи в ElasticSearch, а также вывести в output
                # https://docs.fluentd.org/v0.12/articles/out_copy
  <store>
    @type elasticsearch
    host elasticsearch
    port 9200
    logstash_format true
    logstash_prefix fluentd
    logstash_dateformat %Y%m%d
    include_tag_key true
    type_name access_log
    tag_key @log_name
    flush_interval 1s
  </store>
  <store>
    @type stdout
  </store>
</match>